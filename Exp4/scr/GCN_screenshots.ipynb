{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the original content and citation files\n",
    "content_path = \"citeseer/citeseer.content\"\n",
    "cites_path = \"citeseer/citeseer.cites\"\n",
    "new_content_path = \"citeseer_new/citeseer.content.new\"\n",
    "new_cites_path = \"citeseer_new/citeseer.cites.new\"\n",
    "fr_content = open(content_path, \"r\")\n",
    "fr_cites = open(cites_path, \"r\")\n",
    "fw_content = open(new_content_path, \"w\")\n",
    "fw_cites = open(new_cites_path, \"w\")\n",
    "\n",
    "# ... (Code for processing content and generating new identifiers)\n",
    "\n",
    "# Write the processed content and citation files\n",
    "fw_content.write(temp)\n",
    "fw_cites.write(n1+'\t'+n2+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import json\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    # Function to one-hot encode labels\n",
    "\n",
    "def load_data(dataset, task, self_loop):\n",
    "    # Function to load data for both Cora and Citeseer datasets\n",
    "\n",
    "def normalize(mx):\n",
    "    # Function to row-normalize sparse matrix\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    # Function to calculate accuracy of model predictions\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    # Function to convert a scipy sparse matrix to a torch sparse tensor\n",
    "\n",
    "def load_ppi_data(task='nodecls', self_loop=True):\n",
    "    # Function to load data for the PPI dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        # Initialization of the GCN layer\n",
    "        # ...\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # Resetting parameters during model training\n",
    "        # ...\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        # Forward pass to compute layer output\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        # Representation of the GCN layer\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hid_channels, out_channels, dropout, \n",
    "                 layer_num=2, activation='relu', drop_edge=False, pair_norm=False):\n",
    "        # Initialization of the GCN model\n",
    "        # ...\n",
    "\n",
    "    def forward(self, x, adj, task='nodecls', edges=None, ppi=False):\n",
    "        # Forward pass of the GCN model\n",
    "        # ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your desired values for the arguments\n",
    "class Args:\n",
    "    # Definition of command-line arguments\n",
    "    # ...\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Load data\n",
    "if args.task == 'nodecls':\n",
    "    # Loading data for node classification task\n",
    "    # ...\n",
    "\n",
    "elif args.task == 'linkpred':\n",
    "    # Loading data for link prediction task\n",
    "    # ...\n",
    "\n",
    "# Model and optimizer\n",
    "model = GCN(in_channels=features.shape[1],\n",
    "            hid_channels=args.hidden,\n",
    "            out_channels=labels.max().item() + 1,\n",
    "            dropout=args.dropout,\n",
    "            layer_num=args.layer_num,\n",
    "            activation=args.activate,\n",
    "            drop_edge=args.drop_edge,\n",
    "            pair_norm=args.pair_norm)\n",
    "\n",
    "# Training and evaluation loop\n",
    "for epoch in range(args.epochs):\n",
    "    train(epoch, args.task)\n",
    "\n",
    "# Output the best validation performance\n",
    "output_best(val_performances, test_performances, args.task)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your desired values for the arguments\n",
    "class TestArgs:\n",
    "    # Definition of command-line arguments for testing\n",
    "    # ...\n",
    "\n",
    "test_args = TestArgs()\n",
    "\n",
    "# Load data for testing\n",
    "if test_args.task == 'nodecls':\n",
    "    # Loading data for node classification task\n",
    "    # ...\n",
    "elif test_args.task == 'linkpred':\n",
    "    # Loading data for link prediction task\n",
    "    # ...\n",
    "\n",
    "# Model and optimizer for testing\n",
    "model = GCN(in_channels=features.shape[1],\n",
    "            hid_channels=test_args.hidden,\n",
    "            out_channels=labels.max().item() + 1,\n",
    "            dropout=test_args.dropout,\n",
    "            layer_num=test_args.layer_num,\n",
    "            activation=test_args.activate,\n",
    "            drop_edge=test_args.drop_edge,\n",
    "            pair_norm=test_args.pair_norm)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=test_args.lr, weight_decay=test_args.weight_decay)\n",
    "\n",
    "# Test the model\n",
    "# ...\n",
    "\n",
    "# Evaluate on validation set for parameter tuning\n",
    "# ...\n",
    "\n",
    "# Test the model on the test set\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Top 1 Accuracy over epochs for validation and test sets\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(val_performances, label='Validation', marker='o')\n",
    "plt.plot(test_performances, label='Test', marker='o')\n",
    "plt.title('Top 1 Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Top 1 Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the training loss over epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training Loss', marker='o', color='orange')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
